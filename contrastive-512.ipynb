{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "343eb22b-8ec6-415a-8685-5f6f9fb36bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from transformers import AutoModel, AutoTokenizer, AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from utils import *\n",
    "from contrastive_utils import *\n",
    "import random\n",
    "# from class_balanced_loss import *\n",
    "\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1241836f-79cb-4032-b7d5-1599acd30dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b82a12e-e0b0-4869-935b-b04a261d6489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) |available.\n",
      "We will use the GPU: NVIDIA GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():    \n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) |available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a63a3212-b76f-4ea2-8679-2e6e61a9d3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_contrastive(model, dataloader, tokenizer, optimizer, device, epochs,augment,generation_loss_fn):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "        for batch in progress_bar:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            long_answer_ids = batch['long_answer_ids'].to(device)\n",
    "            \n",
    "            # Create two views of the same batch\n",
    "            aug_input_ids_1, aug_attention_mask_1 = augment(input_ids, attention_mask, tokenizer)\n",
    "            aug_input_ids_2, aug_attention_mask_2 = augment(input_ids, attention_mask, tokenizer)\n",
    "            \n",
    "            proj_1,long_answer_logits_1 = model(aug_input_ids_1, aug_attention_mask_1)\n",
    "            proj_2,long_answer_logits_2 = model(aug_input_ids_2, aug_attention_mask_2)\n",
    "            \n",
    "            loss = contrastive_loss(proj_1, proj_2)\n",
    "            generation_loss = generation_loss_fn(long_answer_logits_1.view(-1, long_answer_logits_1.size(-1)), \n",
    "                                                 long_answer_ids.view(-1)) + generation_loss_fn(long_answer_logits_2.view(-1, long_answer_logits_2.size(-1)), \n",
    "                                                 long_answer_ids.view(-1))\n",
    "\n",
    "            loss += generation_loss\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            progress_bar.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(dataloader):.4f}\")\n",
    "\n",
    "# train_contrastive(model, train_loader, tokenizer, optimizer, device, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ad6b569-1793-4984-a730-3c64a758561c",
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_train_processed,artificial_train_processed,unlabeled_processed,expert_test_processed = load_pubmedqa_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "679ff2de-f7bb-42cb-b59f-ee6075a909a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"dmis-lab/biobert-base-cased-v1.1\"\n",
    "# model_name = \"nlpie/bio-mobilebert\"\n",
    "# model_name = 'nlpie/bio-tinybert'\n",
    "model_name = \"nlpie/tiny-biobert\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41f61517-6dbf-492d-8568-fc315758bd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at nlpie/tiny-biobert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = PubMedQAContrastive(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83829e25-6b09-4fd5-a7c3-26186167bd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PubMedQADataset(expert_train_processed + artificial_train_processed, tokenizer,max_length = 512)\n",
    "unlabeled_dataset = PubMedQADataset(unlabeled_processed, tokenizer,max_length = 512)\n",
    "test_dataset = PubMedQADataset(expert_test_processed,tokenizer,max_length = 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eabe494c-8128-4fcf-9570-5a97f461b1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_path = os.path.join(data_path,\"test_set.json\")\n",
    "df_test = pd.read_json(test_set_path).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a045cfc-d1da-4b6e-84ac-08c8c13979e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23087604"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49e3fc0f-d8ef-4bab-86f3-e84f9b0408ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_class_counts(dataset):\n",
    "    class_counts = Counter()\n",
    "    for data in tqdm(dataset):\n",
    "        label = data['label'].item()\n",
    "        class_counts[label] += 1\n",
    "    return class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac765d84-2067-4b50-840a-7b9a20dcc09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211769/211769 [07:02<00:00, 501.26it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compute class counts and weights\n",
    "class_counts = compute_class_counts(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b605cc43-1341-47d8-b711-75fc2641934e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_count_list = [196420, 15294, 55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd9270dd-caf3-4f83-a1f5-61d371eaee73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_count_list = [class_counts[i] for i in range(len(class_counts))]\n",
    "class_weights = [max(class_count_list) / count for count in class_count_list]\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f86015b4-7cda-45a2-9f7a-af7495a23210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e+00, 1.2843e+01, 3.5713e+03], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9ef5a16-79a0-4da0-85cd-f8139d77452f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "unlabeled_loader = DataLoader(unlabeled_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset,batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49d02838-ab50-42cb-896f-98a2c53c0c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "630fa6c7-eb29-4279-bfeb-586c6548fa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79e74be0-3cf0-40d2-b30d-18306cc55a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a289a977-d970-40e8-ad60-36e2556f3a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2: 100%|██████████| 7657/7657 [29:45<00:00,  4.29it/s, loss=0.000563]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2, Loss: 1.0848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/2: 100%|██████████| 7657/7657 [29:45<00:00,  4.29it/s, loss=6.44e-5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2, Loss: 0.7442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_contrastive(model, unlabeled_loader, tokenizer,optimizer, device, \n",
    "                  num_epochs, augment,generation_loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0e1ceb36-3749-450e-8d1b-65cfdcda132c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'pubmedqa_contrastive_model.pth')\n",
    "\n",
    "state = {\n",
    "    'state_dict': model.state_dict(),\n",
    "    'optimizer': optimizer.state_dict(),\n",
    "    'epochs': 2,\n",
    "    'lr':5e-5\n",
    "}\n",
    "\n",
    "torch.save(state, f\"weights/{model_name.split('/')[1]}_512_contrastive_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b51c5a28-806a-46cc-8574-bdea0f431a6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d26c68fd-b699-4c63-bd98-533ae5e833bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at nlpie/tiny-biobert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the trained contrastive model\n",
    "model = PubMedQAContrastive(model_name).to(device)\n",
    "# model.load_state_dict(torch.load('pubmedqa_contrastive_model.pth'))\n",
    "\n",
    "checkpoint = torch.load(f\"weights/{model_name.split('/')[1]}_512_contrastive_model.pt\")\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "996d21b3-155e-426b-9771-4a3db5f01328",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# Create and train the classifier\n",
    "classifier = PubMedQAClassifier(model).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a435bc96-1308-424f-8ebe-fb530c04023b",
   "metadata": {},
   "source": [
    "Before pre-training = 0.39\n",
    "\n",
    "After pre-training for 2 epochs = 0.522"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e5ac3ed-e19e-43e9-846f-f30e372d3a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy before finetuning : 0.522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Accuracy before finetuning : {get_acc(classifier,test_loader,device)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f83e20-7ef2-4c44-8b0e-7cd87d5cebeb",
   "metadata": {},
   "source": [
    "## PHASE 2 finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86c3e434-5e53-472c-83c2-c6e12c5aa38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_optimizer = torch.optim.AdamW(classifier.parameters(), lr=2e-5)\n",
    "classification_loss_fn = nn.CrossEntropyLoss(weight = class_weights)\n",
    "generation_loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5aa6b03a-9d3a-4e27-9be9-9ccb288757ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(model, dataloader, testloader, optimizer,classification_loss_fn,generation_loss_fn, device, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "        for batch in progress_bar:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            label = batch['label'].to(device)\n",
    "            long_answer_ids = batch['long_answer_ids'].to(device)\n",
    "\n",
    "\n",
    "            classification_logits,long_answer_logits = model(input_ids, attention_mask)\n",
    "            \n",
    "            # Compute losses\n",
    "            classification_loss = classification_loss_fn(classification_logits, label)\n",
    "            # classification_loss = CB_loss(label.to('cpu'), classification_logits.to('cpu'), class_count_list, num_classes,loss_type, beta, gamma)\n",
    "            generation_loss = generation_loss_fn(long_answer_logits.view(-1, long_answer_logits.size(-1)), long_answer_ids.view(-1))\n",
    "    \n",
    "            # Combine losses\n",
    "            loss = classification_loss + generation_loss\n",
    "      \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "                \n",
    "            total_loss += loss.item()\n",
    "            progress_bar.set_postfix({'loss': loss.item()})\n",
    "            \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(dataloader):.4f}\")\n",
    "        print(f\"Test Accuracy : {get_acc(model,testloader,device)}\")\n",
    "        model.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d21f09-5bfe-49a5-a2f1-9553810c4fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  73%|███████▎  | 19254/26472 [40:29<15:10,  7.93it/s, loss=7.97]"
     ]
    }
   ],
   "source": [
    "train_classifier(classifier,labeled_loader,test_loader,classifier_optimizer,classification_loss_fn,\n",
    "                 generation_loss_fn,device,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1172b1c8-c744-4ee9-a897-207c1ccd7e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\n",
    "    'state_dict': classifier.state_dict(),\n",
    "    'optimizer': classifier_optimizer.state_dict(),\n",
    "    'epochs': 1,\n",
    "    'lr':2e-5\n",
    "}\n",
    "\n",
    "torch.save(state, f\"weights/{model_name.split('/')[1]}_512_contrastive_QA_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ec5de02-130a-4803-810a-82d68555b5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(f\"weights/{model_name.split('/')[1]}_512_contrastive_QA_model.pt\")\n",
    "classifier.load_state_dict(checkpoint['state_dict'])\n",
    "classifier_optimizer.load_state_dict(checkpoint['optimizer'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed9100c8-8f07-49f6-a2d3-a81743b7608c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  5.17it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.614"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_acc(classifier,test_loader,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf8f73da-52c3-48bc-a65c-27ab490154f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  5.04it/s]\n"
     ]
    }
   ],
   "source": [
    "save_preds(df_test.index.to_list(),\n",
    "           get_pred(classifier,test_loader,device),\n",
    "           \"tinybiobert_phase_1_phase_2\",\n",
    "          pred_dir=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f745b78-471a-4af1-9f1c-12a6fa3aaa2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee291db-5c8c-4143-9ef1-273372aa9ace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d65769b8-fe19-4437-ab85-304e6ae59f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 26472/26472 [55:44<00:00,  7.92it/s, loss=6.5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Loss: 6.6541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_classifier(classifier,labeled_loader,test_loader,classifier_optimizer,classification_loss_fn,\n",
    "                 generation_loss_fn,device,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b44160-f8c1-4dcf-b049-16ef873eced0",
   "metadata": {},
   "source": [
    "## Without artificial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ffcabbd7-04bc-4efa-b3e3-41592d36b680",
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_train = PubMedQADataset(expert_train_processed, tokenizer,max_length = 512)\n",
    "expert_train_loader = DataLoader(expert_train,batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4a3c75a-9cd4-4da7-b0ea-1758cde994fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 556.28it/s]\n"
     ]
    }
   ],
   "source": [
    "class_counts = compute_class_counts(expert_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "915b05be-cec4-46f1-aeb3-496503f3c4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_count_list = [class_counts[i] for i in range(len(class_counts))]\n",
    "class_weights = [max(class_count_list) / count for count in class_count_list]\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a58f09c2-1362-435c-bfa4-426c69cc25c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_optimizer = torch.optim.AdamW(classifier.parameters(), lr=2e-5)\n",
    "classification_loss_fn = nn.CrossEntropyLoss(weight = class_weights)\n",
    "generation_loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd8b468e-cdb7-4772-aade-0dfde9fcf350",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 63/63 [00:08<00:00,  7.48it/s, loss=12]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Loss: 11.3995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_classifier(classifier,expert_train_loader,test_loader,classifier_optimizer,classification_loss_fn,\n",
    "                 generation_loss_fn,device,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b78ac2a7-a93a-4742-b0b0-6732e070255a",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\n",
    "    'state_dict': classifier.state_dict(),\n",
    "    'optimizer': classifier_optimizer.state_dict(),\n",
    "    'epochs': 1,\n",
    "    'lr':2e-5\n",
    "}\n",
    "\n",
    "torch.save(state, f\"weights/{model_name.split('/')[1]}_512_contrastive_phase_1_phase_2_expert_QA_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4bc0157-c6a1-4d35-b961-605edc8e4997",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  5.14it/s]\n"
     ]
    }
   ],
   "source": [
    "save_preds(df_test.index.to_list(),\n",
    "           get_pred(classifier,test_loader,device),\n",
    "           \"tinybiobert_phase_1_phase_2_expert_only\",\n",
    "          pred_dir=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8370316c-5a00-48c4-bfb2-3ce480c87d83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a59926-9dd8-44e3-8be4-7587e961e0a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9fdcc637-7960-46db-9465-0cb5b4b08689",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f6f999c-e481-4500-88f1-d9a55d4b2af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"predictions/tinybiobert_phase_1_phase_2.json\",'r') as f:\n",
    "    test_preds = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "294baf97-bf0c-4c51-8d44-374fb36b45f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('12377809', 'yes'),\n",
       " ('26163474', 'yes'),\n",
       " ('19100463', 'yes'),\n",
       " ('18537964', 'yes'),\n",
       " ('12913878', 'yes')]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(test_preds.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1812739a-a967-479c-836d-a8a94a2d0ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12377809, 26163474, 19100463, 18537964, 12913878])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.index[:5].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9ba0d752-b817-467c-922f-679abd62f74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6fa6348e-3926-471f-91e5-24df0fd3d3d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QUESTION</th>\n",
       "      <th>CONTEXTS</th>\n",
       "      <th>reasoning_required_pred</th>\n",
       "      <th>final_decision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12377809</th>\n",
       "      <td>Is anorectal endosonography valuable in dyschesia?</td>\n",
       "      <td>[Dyschesia can be provoked by inappropriate defecation movements. The aim of this prospective study was to demonstrate dysfunction of the anal sphincter and/or the musculus (m.) puborectalis in patients with dyschesia using anorectal endosonography., Twenty consecutive patients with a medical history of dyschesia and a control group of 20 healthy subjects underwent linear anorectal endosonography (Toshiba models IUV 5060 and PVL-625 RT). In both groups, the dimensions of the anal sphincter and the m. puborectalis were measured at rest, and during voluntary squeezing and straining. Statistical analysis was performed within and between the two groups., The anal sphincter became paradoxically shorter and/or thicker during straining (versus the resting state) in 85% of patients but in only 35% of control subjects. Changes in sphincter length were statistically significantly different (p&lt;0.01, chi(2) test) in patients compared with control subjects. The m. puborectalis became paradoxically shorter and/or thicker during straining in 80% of patients but in only 30% of controls. Both the changes in length and thickness of the m. puborectalis were significantly different (p&lt;0.01, chi(2) test) in patients versus control subjects.]</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26163474</th>\n",
       "      <td>Is there a connection between sublingual varices and hypertension?</td>\n",
       "      <td>[Sublingual varices have earlier been related to ageing, smoking and cardiovascular disease. The aim of this study was to investigate whether sublingual varices are related to presence of hypertension., In an observational clinical study among 431 dental patients tongue status and blood pressure were documented. Digital photographs of the lateral borders of the tongue for grading of sublingual varices were taken, and blood pressure was measured. Those patients without previous diagnosis of hypertension and with a noted blood pressure ≥ 140 mmHg and/or ≥ 90 mmHg at the dental clinic performed complementary home blood pressure during one week. Those with an average home blood pressure ≥ 135 mmHg and/or ≥ 85 mmHg were referred to the primary health care centre, where three office blood pressure measurements were taken with one week intervals. Two independent blinded observers studied the photographs of the tongues. Each photograph was graded as none/few (grade 0) or medium/severe (grade 1) presence of sublingual varices. Pearson's Chi-square test, Student's t-test, and multiple regression analysis were applied. Power calculation stipulated a study population of 323 patients., An association between sublingual varices and hypertension was found (OR = 2.25, p&lt;0.002). Mean systolic blood pressure was 123 and 132 mmHg in patients with grade 0 and grade 1 sublingual varices, respectively (p&lt;0.0001, CI 95 %). Mean diastolic blood pressure was 80 and 83 mmHg in patients with grade 0 and grade 1 sublingual varices, respectively (p&lt;0.005, CI 95 %). Sublingual varices indicate hypertension with a positive predictive value of 0.5 and a negative predictive value of 0.80.]</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19100463</th>\n",
       "      <td>Is the affinity column-mediated immunoassay method suitable as an alternative to the microparticle enzyme immunoassay method as a blood tacrolimus assay?</td>\n",
       "      <td>[Tacrolimus is a potent immunosuppressive drug used in organ transplantation. Because of its substantial toxic effects, narrow therapeutic index, and interindividual pharmacokinetic variability, therapeutic drug monitoring of whole-blood tacrolimus concentrations has been recommended. We investigated the comparability of the results of 2 immunoassay systems, affinity column-mediated immunoassay (ACMIA) and microparticle enzyme immunoassay (MEIA), comparing differences in the tacrolimus concentrations measured by the 2 methods in relation to the hematologic and biochemical values of hepatic and renal functions., A total of 154 samples from kidney or liver transplant recipients were subjected to Dimension RxL HM with a tacrolimus Flex reagent cartilage for the ACMIA method and IMx tacrolimus II for the MEIA method., Tacrolimus concentrations measured by the ACMIA method (n = 154) closely correlated with those measured by the MEIA method (r = 0.84). The Bland-Altman plot using concentration differences between the 2 methods and the average of the 2 methods showed no specific trends. The tacrolimus levels determined by both the MEIA method and the ACMIA method were not influenced by hematocrit levels, but the difference between the 2 methods (ACMIA - MEIA) tended to be larger in low hematocrit samples (P&lt;.001).]</td>\n",
       "      <td>maybe</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18537964</th>\n",
       "      <td>Does a physician's specialty influence the recording of medication history in patients' case notes?</td>\n",
       "      <td>[To determine the impact of a physician's specialty on the frequency and depth of medication history documented in patient medical records., A cross-sectional assessment of the frequency and depth of medication history information documented by 123 physicians for 900 randomly selected patients stratified across Cardiology, Chest, Dermatology, Endocrine, Gastroenterology, Haematology, Neurology, Psychiatry and Renal specialties was carried out at a 900-bed teaching hospital located in Ibadan, Nigeria., Four hundred and forty-three (49.2%) of the cohort were males and 457 (50.8%) were females; with mean ages 43.2 +/- 18.6 and 43.1 +/- 17.9 years respectively. Physicians' specialties significantly influenced the depth of documentation of the medication history information across the nine specialties (P&lt;0.0001). Post hoc pair-wise comparisons with Tukey's HSD test showed that the mean scores for adverse drug reactions and adherence to medicines was highest in the Cardiology specialty; while the Chest specialty had the highest mean scores for allergy to drugs, food, chemicals and cigarette smoking. Mean scores for the use of alcohol; illicit drugs; dietary restrictions was highest for Gastroenterology, Psychiatry and Endocrine specialties respectively. Physicians' specialties also significantly influenced the frequency of documentation of the medication history across the nine specialties (P&lt;0.0001).]</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12913878</th>\n",
       "      <td>Locoregional opening of the rodent blood-brain barrier for paclitaxel using Nd:YAG laser-induced thermo therapy: a new concept of adjuvant glioma therapy?</td>\n",
       "      <td>[Nd:YAG laser-induced thermo therapy (LITT) of rat brains is associated with blood-brain barrier (BBB) permeability changes. We address the question of whether LITT-induced locoregional disruption of the BBB could possibly allow a locoregional passage of chemotherapeutic agents into brain tissue to treat malignant glioma.STUDY DESIGN/, CD Fischer rats were subject to LITT of the left forebrain. Disruption of the BBB was analyzed using Evans blue and immunohistochemistry (IH). Animals were perfused with paclitaxel, and high-pressure liquid chromatography (HPLC) was employed to analyze the content of paclitaxel in brain and plasma samples., LITT induces an opening of the BBB as demonstrated by locoregional extravasation of Evans blue, C3C, fibrinogen, and IgM. HPLC proved the passage of paclitaxel across the disrupted BBB.]</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                            QUESTION  \\\n",
       "12377809                                                                                                          Is anorectal endosonography valuable in dyschesia?   \n",
       "26163474                                                                                          Is there a connection between sublingual varices and hypertension?   \n",
       "19100463   Is the affinity column-mediated immunoassay method suitable as an alternative to the microparticle enzyme immunoassay method as a blood tacrolimus assay?   \n",
       "18537964                                                         Does a physician's specialty influence the recording of medication history in patients' case notes?   \n",
       "12913878  Locoregional opening of the rodent blood-brain barrier for paclitaxel using Nd:YAG laser-induced thermo therapy: a new concept of adjuvant glioma therapy?   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       CONTEXTS  \\\n",
       "12377809                                                                                                                                                                                                                                                                                                                                                                                                                                                               [Dyschesia can be provoked by inappropriate defecation movements. The aim of this prospective study was to demonstrate dysfunction of the anal sphincter and/or the musculus (m.) puborectalis in patients with dyschesia using anorectal endosonography., Twenty consecutive patients with a medical history of dyschesia and a control group of 20 healthy subjects underwent linear anorectal endosonography (Toshiba models IUV 5060 and PVL-625 RT). In both groups, the dimensions of the anal sphincter and the m. puborectalis were measured at rest, and during voluntary squeezing and straining. Statistical analysis was performed within and between the two groups., The anal sphincter became paradoxically shorter and/or thicker during straining (versus the resting state) in 85% of patients but in only 35% of control subjects. Changes in sphincter length were statistically significantly different (p<0.01, chi(2) test) in patients compared with control subjects. The m. puborectalis became paradoxically shorter and/or thicker during straining in 80% of patients but in only 30% of controls. Both the changes in length and thickness of the m. puborectalis were significantly different (p<0.01, chi(2) test) in patients versus control subjects.]   \n",
       "26163474  [Sublingual varices have earlier been related to ageing, smoking and cardiovascular disease. The aim of this study was to investigate whether sublingual varices are related to presence of hypertension., In an observational clinical study among 431 dental patients tongue status and blood pressure were documented. Digital photographs of the lateral borders of the tongue for grading of sublingual varices were taken, and blood pressure was measured. Those patients without previous diagnosis of hypertension and with a noted blood pressure ≥ 140 mmHg and/or ≥ 90 mmHg at the dental clinic performed complementary home blood pressure during one week. Those with an average home blood pressure ≥ 135 mmHg and/or ≥ 85 mmHg were referred to the primary health care centre, where three office blood pressure measurements were taken with one week intervals. Two independent blinded observers studied the photographs of the tongues. Each photograph was graded as none/few (grade 0) or medium/severe (grade 1) presence of sublingual varices. Pearson's Chi-square test, Student's t-test, and multiple regression analysis were applied. Power calculation stipulated a study population of 323 patients., An association between sublingual varices and hypertension was found (OR = 2.25, p<0.002). Mean systolic blood pressure was 123 and 132 mmHg in patients with grade 0 and grade 1 sublingual varices, respectively (p<0.0001, CI 95 %). Mean diastolic blood pressure was 80 and 83 mmHg in patients with grade 0 and grade 1 sublingual varices, respectively (p<0.005, CI 95 %). Sublingual varices indicate hypertension with a positive predictive value of 0.5 and a negative predictive value of 0.80.]   \n",
       "19100463                                                                                                                                                                                                                                                                                                                                                                      [Tacrolimus is a potent immunosuppressive drug used in organ transplantation. Because of its substantial toxic effects, narrow therapeutic index, and interindividual pharmacokinetic variability, therapeutic drug monitoring of whole-blood tacrolimus concentrations has been recommended. We investigated the comparability of the results of 2 immunoassay systems, affinity column-mediated immunoassay (ACMIA) and microparticle enzyme immunoassay (MEIA), comparing differences in the tacrolimus concentrations measured by the 2 methods in relation to the hematologic and biochemical values of hepatic and renal functions., A total of 154 samples from kidney or liver transplant recipients were subjected to Dimension RxL HM with a tacrolimus Flex reagent cartilage for the ACMIA method and IMx tacrolimus II for the MEIA method., Tacrolimus concentrations measured by the ACMIA method (n = 154) closely correlated with those measured by the MEIA method (r = 0.84). The Bland-Altman plot using concentration differences between the 2 methods and the average of the 2 methods showed no specific trends. The tacrolimus levels determined by both the MEIA method and the ACMIA method were not influenced by hematocrit levels, but the difference between the 2 methods (ACMIA - MEIA) tended to be larger in low hematocrit samples (P<.001).]   \n",
       "18537964                                                                                                                                                                                                                                                                            [To determine the impact of a physician's specialty on the frequency and depth of medication history documented in patient medical records., A cross-sectional assessment of the frequency and depth of medication history information documented by 123 physicians for 900 randomly selected patients stratified across Cardiology, Chest, Dermatology, Endocrine, Gastroenterology, Haematology, Neurology, Psychiatry and Renal specialties was carried out at a 900-bed teaching hospital located in Ibadan, Nigeria., Four hundred and forty-three (49.2%) of the cohort were males and 457 (50.8%) were females; with mean ages 43.2 +/- 18.6 and 43.1 +/- 17.9 years respectively. Physicians' specialties significantly influenced the depth of documentation of the medication history information across the nine specialties (P<0.0001). Post hoc pair-wise comparisons with Tukey's HSD test showed that the mean scores for adverse drug reactions and adherence to medicines was highest in the Cardiology specialty; while the Chest specialty had the highest mean scores for allergy to drugs, food, chemicals and cigarette smoking. Mean scores for the use of alcohol; illicit drugs; dietary restrictions was highest for Gastroenterology, Psychiatry and Endocrine specialties respectively. Physicians' specialties also significantly influenced the frequency of documentation of the medication history across the nine specialties (P<0.0001).]   \n",
       "12913878                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      [Nd:YAG laser-induced thermo therapy (LITT) of rat brains is associated with blood-brain barrier (BBB) permeability changes. We address the question of whether LITT-induced locoregional disruption of the BBB could possibly allow a locoregional passage of chemotherapeutic agents into brain tissue to treat malignant glioma.STUDY DESIGN/, CD Fischer rats were subject to LITT of the left forebrain. Disruption of the BBB was analyzed using Evans blue and immunohistochemistry (IH). Animals were perfused with paclitaxel, and high-pressure liquid chromatography (HPLC) was employed to analyze the content of paclitaxel in brain and plasma samples., LITT induces an opening of the BBB as demonstrated by locoregional extravasation of Evans blue, C3C, fibrinogen, and IgM. HPLC proved the passage of paclitaxel across the disrupted BBB.]   \n",
       "\n",
       "         reasoning_required_pred final_decision  \n",
       "12377809                     yes            yes  \n",
       "26163474                     yes            yes  \n",
       "19100463                   maybe            yes  \n",
       "18537964                     yes            yes  \n",
       "12913878                     yes            yes  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()[['QUESTION','CONTEXTS','reasoning_required_pred','final_decision']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f60fef-2217-4e21-b647-72d300487d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
